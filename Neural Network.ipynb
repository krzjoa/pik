{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from preprocess import preprocess_train, preprocess, FEATURES, CATEGORICAL_FEATURES, TEST_FEATURES, CATEGORICAL_TEST_FEATURES_IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X, y = preprocess_train(train, categotical_features=CATEGORICAL_FEATURES, features=TEST_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X, y = shuffle(X, y)\n",
    "y = y[:, None]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scale data\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8716, 1)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Feature preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def encode_categorical(X, cat_feat):\n",
    "    '''\n",
    "    Encodes categorical features with one-hot encoding and adds it into model\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: numpy.ndarray\n",
    "        Training features\n",
    "    cat_feat: list of int\n",
    "        Categorical features indices\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tweaked_X: numpy.ndarray\n",
    "        Tweaked X\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    # All the rest\n",
    "    rest = np.ones(X.shape[1], np.bool)\n",
    "    rest[cat_feat] = False\n",
    "    \n",
    "    X_rest = X[:, rest]\n",
    "    \n",
    "    # Encoded\n",
    "    one_hot_encoded = []\n",
    "    \n",
    "    for col_idx in cat_feat:  \n",
    "        encoded = label_binarize(X[:, col_idx], np.unique(X[:, col_idx]).astype(int))\n",
    "        \n",
    "        #print encoded.shape\n",
    "        \n",
    "        one_hot_encoded.append(\n",
    "            encoded\n",
    "        )\n",
    "    \n",
    "    one_hot_encoded.append(X_rest)\n",
    "    \n",
    "    return np.hstack(one_hot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "encoded_X = encode_categorical(X, CATEGORICAL_TEST_FEATURES_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded_X = scaler.fit_transform(encoded_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8716, 44) (8716, 46)\n"
     ]
    }
   ],
   "source": [
    "print X.shape, encoded_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_iterator(X, y, batch_size):\n",
    "    for i in range(0, len(X) - batch_size, batch_size):\n",
    "        yield X[i:i+batch_size], y[i:i+batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### CrossVal mean scores\n",
    "* catboost_d10: 224.01548277848525\n",
    "* catboost_d16: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Training simple model\n",
    "from sklearn.model_selection import KFold\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch 1 Loss:410.180603027 Val loss: 363.491912842\n",
      "Epoch 2 Loss:335.192474365 Val loss: 337.040527344\n",
      "Epoch 3 Loss:326.756652832 Val loss: 332.833007812\n",
      "Epoch 4 Loss:323.076660156 Val loss: 329.865570068\n",
      "Epoch 5 Loss:320.066619873 Val loss: 327.182891846\n",
      "Epoch 6 Loss:317.193725586 Val loss: 324.506561279\n",
      "Epoch 7 Loss:314.280670166 Val loss: 321.781738281\n",
      "Epoch 8 Loss:311.285949707 Val loss: 318.946380615\n",
      "Epoch 9 Loss:308.227508545 Val loss: 316.056365967\n",
      "Epoch 10 Loss:305.174438477 Val loss: 313.179840088\n",
      "Epoch 11 Loss:302.172088623 Val loss: 310.364868164\n",
      "Epoch 12 Loss:299.287902832 Val loss: 307.690307617\n",
      "Epoch 13 Loss:296.58895874 Val loss: 305.201324463\n",
      "Epoch 14 Loss:294.095977783 Val loss: 302.947113037\n",
      "Epoch 15 Loss:291.816040039 Val loss: 300.932220459\n",
      "Epoch 16 Loss:289.730529785 Val loss: 299.136779785\n",
      "Epoch 17 Loss:287.822265625 Val loss: 297.557098389\n",
      "Epoch 18 Loss:286.094177246 Val loss: 296.180023193\n",
      "Epoch 19 Loss:284.538299561 Val loss: 294.985015869\n",
      "Epoch 20 Loss:283.131622314 Val loss: 293.949707031\n",
      "Epoch 21 Loss:281.84777832 Val loss: 293.04309082\n",
      "Epoch 22 Loss:280.664398193 Val loss: 292.2265625\n",
      "Epoch 23 Loss:279.563903809 Val loss: 291.492279053\n",
      "Epoch 24 Loss:278.541259766 Val loss: 290.856414795\n",
      "Epoch 25 Loss:277.596496582 Val loss: 290.282196045\n",
      "Epoch 26 Loss:276.706756592 Val loss: 289.751434326\n",
      "Epoch 27 Loss:275.862060547 Val loss: 289.254943848\n",
      "Epoch 28 Loss:275.058288574 Val loss: 288.782623291\n",
      "Epoch 29 Loss:274.287414551 Val loss: 288.335571289\n",
      "Epoch 30 Loss:273.539672852 Val loss: 287.914245605\n",
      "Epoch 31 Loss:272.8097229 Val loss: 287.511199951\n",
      "Epoch 32 Loss:272.095550537 Val loss: 287.129669189\n",
      "Epoch 33 Loss:271.405517578 Val loss: 286.764099121\n",
      "Epoch 34 Loss:270.738677979 Val loss: 286.405578613\n",
      "Epoch 35 Loss:270.092834473 Val loss: 286.059967041\n",
      "Epoch 36 Loss:269.467010498 Val loss: 285.721557617\n",
      "Epoch 37 Loss:268.857818604 Val loss: 285.391296387\n",
      "Epoch 38 Loss:268.263549805 Val loss: 285.069641113\n",
      "Epoch 39 Loss:267.682983398 Val loss: 284.755828857\n",
      "Epoch 40 Loss:267.11517334 Val loss: 284.450042725\n",
      "Epoch 41 Loss:266.558807373 Val loss: 284.148895264\n",
      "Epoch 42 Loss:266.010894775 Val loss: 283.853790283\n",
      "Epoch 43 Loss:265.467590332 Val loss: 283.563323975\n",
      "Epoch 44 Loss:264.929351807 Val loss: 283.277252197\n",
      "Epoch 45 Loss:264.395965576 Val loss: 283.000396729\n",
      "Epoch 46 Loss:263.865509033 Val loss: 282.735992432\n",
      "Epoch 47 Loss:263.340148926 Val loss: 282.479125977\n",
      "Epoch 48 Loss:262.818786621 Val loss: 282.228820801\n",
      "Epoch 49 Loss:262.300231934 Val loss: 281.985565186\n",
      "Epoch 50 Loss:261.785003662 Val loss: 281.745025635\n",
      "Epoch 51 Loss:261.273284912 Val loss: 281.51159668\n",
      "Epoch 52 Loss:260.764953613 Val loss: 281.281799316\n",
      "Epoch 53 Loss:260.258331299 Val loss: 281.056274414\n",
      "Epoch 54 Loss:259.75201416 Val loss: 280.833618164\n",
      "Epoch 55 Loss:259.246398926 Val loss: 280.615234375\n",
      "Epoch 56 Loss:258.742675781 Val loss: 280.400604248\n",
      "Epoch 57 Loss:258.240447998 Val loss: 280.185516357\n",
      "Epoch 58 Loss:257.739440918 Val loss: 279.97354126\n",
      "Epoch 59 Loss:257.238220215 Val loss: 279.767272949\n",
      "Epoch 60 Loss:256.736907959 Val loss: 279.568450928\n",
      "Epoch 61 Loss:256.236633301 Val loss: 279.376495361\n",
      "Epoch 62 Loss:255.737869263 Val loss: 279.188690186\n",
      "Epoch 63 Loss:255.240844727 Val loss: 279.006317139\n",
      "Epoch 64 Loss:254.745056152 Val loss: 278.828552246\n",
      "Epoch 65 Loss:254.25177002 Val loss: 278.654846191\n",
      "Epoch 66 Loss:253.761978149 Val loss: 278.48449707\n",
      "Epoch 67 Loss:253.275802612 Val loss: 278.316894531\n",
      "Epoch 68 Loss:252.792419434 Val loss: 278.148071289\n",
      "Epoch 69 Loss:252.31072998 Val loss: 277.978302002\n",
      "Epoch 70 Loss:251.830230713 Val loss: 277.810424805\n",
      "Epoch 71 Loss:251.350189209 Val loss: 277.645263672\n",
      "Epoch 72 Loss:250.87121582 Val loss: 277.48425293\n",
      "Epoch 73 Loss:250.393356323 Val loss: 277.327667236\n",
      "Epoch 74 Loss:249.91746521 Val loss: 277.173217773\n",
      "Epoch 75 Loss:249.444641113 Val loss: 277.021240234\n",
      "Epoch 76 Loss:248.973922729 Val loss: 276.868591309\n",
      "Epoch 77 Loss:248.504989624 Val loss: 276.717498779\n",
      "Epoch 78 Loss:248.037628174 Val loss: 276.56741333\n",
      "Epoch 79 Loss:247.573165894 Val loss: 276.419219971\n",
      "Epoch 80 Loss:247.112869263 Val loss: 276.27520752\n",
      "Epoch 81 Loss:246.656585693 Val loss: 276.137298584\n",
      "Epoch 82 Loss:246.204162598 Val loss: 276.003204346\n",
      "Epoch 83 Loss:245.75642395 Val loss: 275.872253418\n",
      "Epoch 84 Loss:245.31312561 Val loss: 275.745056152\n",
      "Epoch 85 Loss:244.874282837 Val loss: 275.619110107\n",
      "Epoch 86 Loss:244.439224243 Val loss: 275.495574951\n",
      "Epoch 87 Loss:244.007568359 Val loss: 275.374176025\n",
      "Epoch 88 Loss:243.578796387 Val loss: 275.253173828\n",
      "Epoch 89 Loss:243.152633667 Val loss: 275.136291504\n",
      "Epoch 90 Loss:242.729385376 Val loss: 275.020965576\n",
      "Epoch 91 Loss:242.309295654 Val loss: 274.908203125\n",
      "Epoch 92 Loss:241.892990112 Val loss: 274.797332764\n",
      "Epoch 93 Loss:241.479171753 Val loss: 274.687194824\n",
      "Epoch 94 Loss:241.068328857 Val loss: 274.578704834\n",
      "Epoch 95 Loss:240.659820557 Val loss: 274.471923828\n",
      "Epoch 96 Loss:240.254318237 Val loss: 274.369720459\n",
      "Epoch 97 Loss:239.852310181 Val loss: 274.270751953\n",
      "Epoch 98 Loss:239.453125 Val loss: 274.172210693\n",
      "Epoch 99 Loss:239.056564331 Val loss: 274.072296143\n",
      "Epoch 100 Loss:238.661712646 Val loss: 273.97354126\n",
      "Fold 2\n",
      "Epoch 1 Loss:404.460510254 Val loss: 413.552520752\n",
      "Epoch 2 Loss:332.034179688 Val loss: 391.221221924\n",
      "Epoch 3 Loss:324.652038574 Val loss: 387.210418701\n",
      "Epoch 4 Loss:321.066131592 Val loss: 384.342987061\n",
      "Epoch 5 Loss:318.17565918 Val loss: 381.960418701\n",
      "Epoch 6 Loss:315.570983887 Val loss: 379.799072266\n",
      "Epoch 7 Loss:313.075653076 Val loss: 377.750976562\n",
      "Epoch 8 Loss:310.62677002 Val loss: 375.725799561\n",
      "Epoch 9 Loss:308.18927002 Val loss: 373.614685059\n",
      "Epoch 10 Loss:305.766113281 Val loss: 371.414550781\n",
      "Epoch 11 Loss:303.386566162 Val loss: 369.214599609\n",
      "Epoch 12 Loss:301.066040039 Val loss: 367.033752441\n",
      "Epoch 13 Loss:298.810882568 Val loss: 364.882446289\n",
      "Epoch 14 Loss:296.613067627 Val loss: 362.77255249\n",
      "Epoch 15 Loss:294.46685791 Val loss: 360.714202881\n",
      "Epoch 16 Loss:292.395355225 Val loss: 358.717163086\n",
      "Epoch 17 Loss:290.415405273 Val loss: 356.804626465\n",
      "Epoch 18 Loss:288.539215088 Val loss: 354.999572754\n",
      "Epoch 19 Loss:286.776275635 Val loss: 353.312133789\n",
      "Epoch 20 Loss:285.125854492 Val loss: 351.741943359\n",
      "Epoch 21 Loss:283.58605957 Val loss: 350.288299561\n",
      "Epoch 22 Loss:282.150604248 Val loss: 348.94241333\n",
      "Epoch 23 Loss:280.810546875 Val loss: 347.693603516\n",
      "Epoch 24 Loss:279.557434082 Val loss: 346.537841797\n",
      "Epoch 25 Loss:278.385650635 Val loss: 345.472839355\n",
      "Epoch 26 Loss:277.28302002 Val loss: 344.484436035\n",
      "Epoch 27 Loss:276.23840332 Val loss: 343.56060791\n",
      "Epoch 28 Loss:275.243591309 Val loss: 342.693359375\n",
      "Epoch 29 Loss:274.291687012 Val loss: 341.876922607\n",
      "Epoch 30 Loss:273.378936768 Val loss: 341.109191895\n",
      "Epoch 31 Loss:272.499633789 Val loss: 340.384429932\n",
      "Epoch 32 Loss:271.649078369 Val loss: 339.70211792\n",
      "Epoch 33 Loss:270.820587158 Val loss: 339.058410645\n",
      "Epoch 34 Loss:270.013183594 Val loss: 338.44644165\n",
      "Epoch 35 Loss:269.226165771 Val loss: 337.86517334\n",
      "Epoch 36 Loss:268.454956055 Val loss: 337.304199219\n",
      "Epoch 37 Loss:267.697906494 Val loss: 336.7706604\n",
      "Epoch 38 Loss:266.956756592 Val loss: 336.25869751\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "fold_num = 1\n",
    "\n",
    "for train, test in kfold.split(encoded_X):\n",
    "   \n",
    "    print \"Fold {}\".format(fold_num)\n",
    "    \n",
    "    X_train, X_test = encoded_X[train], encoded_X[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "    \n",
    "    # Create validation datasest\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train)\n",
    "    \n",
    "    # Model\n",
    "    input_var = tf.placeholder(tf.float32, shape=[None, X_train.shape[1]])\n",
    "    gt_var = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "    \n",
    "    model = tf.layers.dense(input_var, 100, activation=tf.nn.elu)\n",
    "    model = tf.layers.dense(model, 100, activation=tf.nn.elu)\n",
    "    output = tf.layers.dense(model, 1) \n",
    "    \n",
    "    # Loss function \n",
    "    loss = tf.reduce_mean(tf.losses.mean_squared_error(gt_var, output)**.5 )\n",
    "    opt = tf.train.AdamOptimizer().minimize(loss)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "  \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for epoch in range(1, EPOCHS+1):  \n",
    "            epoch_loss = []\n",
    "            for X_batch, y_batch in batch_iterator(X_train, y_train, BATCH_SIZE):\n",
    "                batch_loss, pred, _ = sess.run([loss, output, opt], feed_dict={input_var: X_batch, gt_var: y_batch})                      \n",
    "                epoch_loss.append(batch_loss)                                \n",
    "             # Validation\n",
    "            val_loss = sess.run(loss, feed_dict={input_var: X_val, gt_var: y_val})\n",
    "                                               \n",
    "            print \"Epoch {} Loss:{} Val loss: {}\".format(epoch, np.mean(epoch_loss), val_loss)\n",
    "        fold_num += 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# scorer = make_scorer(lambda a, b: mean_squared_error(a, b)**.5)\n",
    "# scores = cross_val_score(lr, encoded_X, y, cv=5, scoring=scorer, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "340.449211318938"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 284.83019248\n"
     ]
    }
   ],
   "source": [
    "y_pred = cbr.fit(X_train, y_train, cat_features=CATEGORICAL_TEST_FEATURES_IDX).predict(X_test)\n",
    "print \"Mean squared error: {}\".format(mean_squared_error(y_test, y_pred)**.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core._CatBoostBase at 0x7f8a7f594a50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make submission\n",
    "cbr.fit(X, y, cat_features=CATEGORICAL_TEST_FEATURES_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test = preprocess(test, CATEGORICAL_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = test[TEST_FEATURES].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "predictions = cbr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 879.78794459, 1165.70020084,  279.39788828, ...,  154.47198918,\n",
       "        -62.34725293,   36.55400176])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def make_submission(ids, predictions):\n",
    "    df = pd.concat([ids, pd.Series(predictions)], axis=1)\n",
    "    return df.rename(columns={0: 'value'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "l = test.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([test.id, pd.Series(predictions)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = df.rename(columns={0: 'value'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"catboost_d10.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
